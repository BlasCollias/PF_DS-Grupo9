{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTEBOOK DE SAGEMAKER: SE CONECTA A REDSHIFT, Y CARGA LOS RESULTADOS A OTRA TABLA, TAMBIEN EN REDSHIFT. DE AHI PASAN A QUICKSIGHT COMO PARTE DEL DASHBOARD. \n",
    "\n",
    "------------------------------\n",
    "TOPIC MODELLING PARA review_comments , separados por review_score\n",
    "\n",
    "Tipo de modelo de ML UNSUPERVISED\n",
    "\n",
    "VERSION 1, SIN SUBCLASE DE stemmer. (devuelve practicamente mismo rsltds que el 'NewLDA')\n",
    "\n",
    "Output a pd.Dataframe. \n",
    "\n",
    "VER ELECCION PARAMETROS.  version final esta en: ngram_range=(2,4), n_topics=3, n_top_words=3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redshift_connector\n",
    "import pandas as pd\n",
    "\n",
    "conn = redshift_connector.connect(\n",
    "     host='redshift-cluster-1.cpop3m8tfd5a.us-east-1.redshift.amazonaws.com',\n",
    "     database='olistdb',\n",
    "     port=5439,\n",
    "     user='awsuser',\n",
    "     password='JldMVsOw&7xL'\n",
    "  )\n",
    "\n",
    "conn.autocommit = True\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "with conn.cursor() as cursor:\n",
    "    cursor.execute(\"SELECT review_id, order_id, review_score, review_comment_message, review_creation_date FROM \\\"olistdb\\\".\\\"public\\\".\\\"order_reviews\\\";\")\n",
    "    Review: pd.DataFrame = cursor.fetch_dataframe()\n",
    "\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/moncho/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.pipeline import make_pipeline\n",
    "#\n",
    "import nltk\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "#import Stemmer\n",
    "#Para traducir la salida: \n",
    "#from deep_translator import GoogleTranslator\n",
    "#import matplotlib as plt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#hay varios q no se usan, del otro archivo. limpiar. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparamos los datos que usamos:\n",
    "#Review = pd.read_csv('Datasets/olist_order_reviews_dataset.csv')\n",
    "\n",
    "#VER FILTRO POR FECHA: \n",
    "#si lo filtra con queries o aca. \n",
    "\n",
    "# tiro nulos por 'comment_message': \n",
    "Review.dropna(subset = 'review_comment_message', inplace= True)\n",
    "\n",
    "# me quedo solo con estas cols: TMB AGREGO FECHA A VER SI SE PUEDE PLOTTEAR\n",
    "Review = Review[['review_score', 'review_comment_message', 'review_id','review_creation_date']] #ie solo tiro review_score\n",
    "\n",
    "# los separo por score, para poder sacarle los 'topic' por separado a cada uno:\n",
    "estrella_1 = Review[Review['review_score'] == 1]\n",
    "estrella_2 = Review[Review['review_score'] == 2]\n",
    "estrella_3 = Review[Review['review_score'] == 3]\n",
    "estrella_4 = Review[Review['review_score'] == 4]\n",
    "estrella_5 = Review[Review['review_score'] == 5]\n",
    "#de cada uno me quedo con la lista de mensajes: \n",
    "comments1=estrella_1['review_comment_message'] \n",
    "comments2=estrella_2['review_comment_message']  \n",
    "comments3=estrella_3['review_comment_message']   \n",
    "comments4=estrella_4['review_comment_message']   \n",
    "comments5=estrella_5['review_comment_message'] \n",
    "#los meto en una lista para poder iterar: \n",
    "comentarios=[comments1, comments2, comments3, comments4, comments5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista STOPWORDS: \n",
    "\n",
    "stoplist_ampliada = stopwords.words('portuguese') + ['produto', 'satisfeita', 'n','recomendo', 'recom']\n",
    "# VER: agregar el 'aun' (en pt)?\n",
    "\n",
    "#veo de quitarle el 'no', asi arma mas frases con sentido de negacion...\n",
    "stoplist_ampliada.remove('não')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moncho/Library/Python/3.9/lib/python/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#iteramos sobre lista 'comentarios' y guardamos todo en un diccionario para pasarlo a DataFrame, y luego a Redshift:\n",
    "dict={} \n",
    "#OBS: PARAMETROS: \n",
    "# los de TfidfVectorizer: stop_words=stoplist_ampliada, ngram_range=(2,4),min_df=5, max_df=0.7)\n",
    "# n_top_words y n_components\n",
    "\n",
    "for i, comment in enumerate (comentarios, 1): #lo inicio en i=1.\n",
    "\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words=stoplist_ampliada, ngram_range=(2,4),min_df=5, max_df=0.7) \n",
    "    lda = LatentDirichletAllocation(n_components=3)   #n_components=3 ?\n",
    "    pipe = make_pipeline(tfidf_vectorizer, lda)\n",
    "\n",
    "    # instancio traductor:\n",
    "    #traductor = GoogleTranslator(source='pt', target='es')\n",
    "\n",
    "    pipe.fit(comment) \n",
    "\n",
    "    lista=[]\n",
    "    n_top_words=3   #n_top_words=3\n",
    "    \n",
    "    for topic_idx, topic in enumerate(lda.components_):\n",
    "        message = ''    #\"Topic #%d: \" % topic_idx  #le saco esto para que no moleste en el df. \n",
    "        message += \", \".join([tfidf_vectorizer.get_feature_names()[i]  #traductor.translate(tfidf_vectorizer.get_feature_names()[i])\n",
    "                                    for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        \n",
    "        lista.append(message)\n",
    "    dict.update({'score '+str(i):lista})\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_redshift=pd.DataFrame(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score 1</th>\n",
       "      <th>score 2</th>\n",
       "      <th>score 3</th>\n",
       "      <th>score 4</th>\n",
       "      <th>score 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>não recebi, ainda não, não chegou</td>\n",
       "      <td>não gostei, veio defeito, não chegou</td>\n",
       "      <td>não veio, prazo entrega, tudo certo</td>\n",
       "      <td>entregue prazo, tudo ok, ainda não</td>\n",
       "      <td>antes prazo, entregue antes, bem antes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>não entregue, não gostei, dinheiro volta</td>\n",
       "      <td>não recebi, ainda não, ainda não recebi</td>\n",
       "      <td>não recebi, ainda não, dentro prazo</td>\n",
       "      <td>antes prazo, chegou antes, tudo certo</td>\n",
       "      <td>antes prazo, entrega rápida, chegou antes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>agora não, recebi apenas, não veio</td>\n",
       "      <td>não veio, nota fiscal, antes prazo</td>\n",
       "      <td>antes prazo, não gostei, não chegou</td>\n",
       "      <td>dentro prazo, entrega rápida, boa qualidade</td>\n",
       "      <td>ótima qualidade, boa qualidade, entrega super</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    score 1  \\\n",
       "0         não recebi, ainda não, não chegou   \n",
       "1  não entregue, não gostei, dinheiro volta   \n",
       "2        agora não, recebi apenas, não veio   \n",
       "\n",
       "                                   score 2  \\\n",
       "0     não gostei, veio defeito, não chegou   \n",
       "1  não recebi, ainda não, ainda não recebi   \n",
       "2       não veio, nota fiscal, antes prazo   \n",
       "\n",
       "                               score 3  \\\n",
       "0  não veio, prazo entrega, tudo certo   \n",
       "1  não recebi, ainda não, dentro prazo   \n",
       "2  antes prazo, não gostei, não chegou   \n",
       "\n",
       "                                       score 4  \\\n",
       "0           entregue prazo, tudo ok, ainda não   \n",
       "1        antes prazo, chegou antes, tudo certo   \n",
       "2  dentro prazo, entrega rápida, boa qualidade   \n",
       "\n",
       "                                         score 5  \n",
       "0         antes prazo, entregue antes, bem antes  \n",
       "1      antes prazo, entrega rápida, chegou antes  \n",
       "2  ótima qualidade, boa qualidade, entrega super  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#topics_redshift.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = redshift_connector.connect(\n",
    "     host='redshift-cluster-1.cpop3m8tfd5a.us-east-1.redshift.amazonaws.com',\n",
    "     database='olistdb',\n",
    "     port=5439,\n",
    "     user='awsuser',\n",
    "     password='JldMVsOw&7xL'\n",
    "  )\n",
    "\n",
    "conn.autocommit = True\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "with conn.cursor() as cursor:\n",
    "    cursor.execute('create table public.ml_lda_topics (score_1 varchar(500), score_2 varchar(500), score_3 varchar(500), score_4 varchar(500), score_5 varchar(500));')\n",
    "    cursor.execute('SELECT * FROM public.ml_lda_topics;')\n",
    "    result = cursor.fetchall()\n",
    "print(result)\n",
    "\n",
    "with conn.cursor() as cursor:\n",
    "    cursor.write_dataframe(topics_redshift, \"ml_lda_topics\")\n",
    "    cursor.execute('SELECT * FROM \"public\".\"ml_lda_topics\";')\n",
    "    result: pd.DataFrame = cursor.fetch_dataframe()\n",
    "\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
